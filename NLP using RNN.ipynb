{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cd32773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3659076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b4bc2722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text   \n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...  \\\n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('spam_ham.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5132fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5171 entries, 0 to 5170\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  5171 non-null   int64 \n",
      " 1   label       5171 non-null   object\n",
      " 2   text        5171 non-null   object\n",
      " 3   label_num   5171 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 161.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fd8c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00d51184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c512610c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c5b07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['v2']\n",
    "y=df['v1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "094d063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['text']\n",
    "y=df['label_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6a8206d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88454c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=1000,lower=True)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train=tokenizer.texts_to_sequences(X_train)\n",
    "X_test=tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28d57680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9,\n",
       " 52,\n",
       " 647,\n",
       " 635,\n",
       " 1,\n",
       " 942,\n",
       " 1,\n",
       " 16,\n",
       " 15,\n",
       " 399,\n",
       " 14,\n",
       " 17,\n",
       " 3,\n",
       " 824,\n",
       " 55,\n",
       " 152,\n",
       " 311,\n",
       " 4,\n",
       " 187,\n",
       " 398,\n",
       " 26,\n",
       " 16,\n",
       " 1,\n",
       " 737,\n",
       " 391,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 418,\n",
       " 603,\n",
       " 362,\n",
       " 85,\n",
       " 232,\n",
       " 61,\n",
       " 105,\n",
       " 85,\n",
       " 70,\n",
       " 3,\n",
       " 196,\n",
       " 114,\n",
       " 452,\n",
       " 18,\n",
       " 143,\n",
       " 44,\n",
       " 1,\n",
       " 9,\n",
       " 647,\n",
       " 196,\n",
       " 1,\n",
       " 17,\n",
       " 728,\n",
       " 3,\n",
       " 152,\n",
       " 647,\n",
       " 84,\n",
       " 26,\n",
       " 11,\n",
       " 144,\n",
       " 111,\n",
       " 21,\n",
       " 242,\n",
       " 8,\n",
       " 931,\n",
       " 21,\n",
       " 242,\n",
       " 14,\n",
       " 2,\n",
       " 7,\n",
       " 43,\n",
       " 26,\n",
       " 55,\n",
       " 4,\n",
       " 692,\n",
       " 2,\n",
       " 293,\n",
       " 217,\n",
       " 684,\n",
       " 1,\n",
       " 17,\n",
       " 66,\n",
       " 26,\n",
       " 55,\n",
       " 285,\n",
       " 4,\n",
       " 187,\n",
       " 242,\n",
       " 40,\n",
       " 591,\n",
       " 16,\n",
       " 17,\n",
       " 648,\n",
       " 3,\n",
       " 692,\n",
       " 26,\n",
       " 380,\n",
       " 4,\n",
       " 231,\n",
       " 254,\n",
       " 274,\n",
       " 3,\n",
       " 239,\n",
       " 134,\n",
       " 874,\n",
       " 97,\n",
       " 320,\n",
       " 21,\n",
       " 16,\n",
       " 17,\n",
       " 152,\n",
       " 728,\n",
       " 3,\n",
       " 193,\n",
       " 376,\n",
       " 440,\n",
       " 111,\n",
       " 21,\n",
       " 242,\n",
       " 15,\n",
       " 399,\n",
       " 1,\n",
       " 62,\n",
       " 6,\n",
       " 25,\n",
       " 109,\n",
       " 1,\n",
       " 635]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "52da0b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7,   2,  11, ...,   2,  42, 131],\n",
       "       [  9, 259, 182, ...,   0,   0,   0],\n",
       "       [  9,   1,  22, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [213,   2, 298, ...,  35, 913, 351],\n",
       "       [  9,  95,   7, ...,   0,   0,   0],\n",
       "       [  9,   4, 724, ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "X_train=pad_sequences(X_train,padding='post',maxlen=100)\n",
    "X_test=pad_sequences(X_test,padding='post',maxlen=100)\n",
    "X_train[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c13ec24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'ham'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_categorical\n\u001b[1;32m----> 2\u001b[0m y_train\u001b[38;5;241m=\u001b[39m\u001b[43mto_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m y_test\u001b[38;5;241m=\u001b[39mto_categorical(y_test,num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      4\u001b[0m y_train\n",
      "File \u001b[1;32mE:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\utils\\np_utils.py:62\u001b[0m, in \u001b[0;36mto_categorical\u001b[1;34m(y, num_classes, dtype)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.utils.to_categorical\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_categorical\u001b[39m(y, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a class vector (integers) to binary class matrix.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m    E.g. for use with `categorical_crossentropy`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    [0. 0. 0. 0.]\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 62\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# Shrink the last dimension if the shape is (..., 1).\u001b[39;00m\n",
      "File \u001b[1;32mE:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\pandas\\core\\series.py:922\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    921\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m--> 922\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    924\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'ham'"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train=to_categorical(y_train,num_classes=2)\n",
    "y_test=to_categorical(y_test,num_classes=2)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ff29be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "label_mapping = {'ham': 0, 'spam': 1}\n",
    "y_train_numeric = [label_mapping[label] for label in y_train]\n",
    "y_test_numeric = [label_mapping[label] for label in y_test]\n",
    "\n",
    "# Convert numerical labels to one-hot encoded format\n",
    "y_train_encoded = to_categorical(y_train_numeric, num_classes=2)\n",
    "y_test_encoded = to_categorical(y_test_numeric, num_classes=2)\n",
    "\n",
    "print(y_train_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cacc5f",
   "metadata": {},
   "source": [
    "### Modeling using Sequential model in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2e05d36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4136, 100, 1)\n",
      "(1035, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,SimpleRNN\n",
    "from keras import optimizers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "X_train=np.array(X_train).reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "print(X_train.shape)\n",
    "X_test=np.array(X_test).reshape((X_test.shape[0],X_test.shape[1],1))\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7f472425",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn():\n",
    "    from keras.optimizers import RMSprop\n",
    "    model=Sequential()\n",
    "    model.add(SimpleRNN(100,input_shape=(100,1),return_sequences=False))\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='LeakyReLU'))\n",
    "    model.add(Dense(2,activation='softmax'))\n",
    "    model.summary()\n",
    "    rmsprop=RMSprop(lr=0.01)\n",
    "    adam=optimizers.Adam(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=rmsprop,metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6cd36c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_16 (SimpleRNN)   (None, 100)               10200     \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 128)               12928     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,530\n",
      "Trainable params: 33,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksha\\AppData\\Local\\Temp\\ipykernel_17624\\69373549.py:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model=KerasClassifier(build_fn=rnn,epochs=20,batch_size=100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 2s 17ms/step - loss: 0.7420 - accuracy: 0.6825\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 1s 15ms/step - loss: 0.6215 - accuracy: 0.6941\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6085 - accuracy: 0.7041\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6046 - accuracy: 0.7002\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5985 - accuracy: 0.7077\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5995 - accuracy: 0.7041\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.6013 - accuracy: 0.7074\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5987 - accuracy: 0.7072\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5956 - accuracy: 0.7079\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5975 - accuracy: 0.7070\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5945 - accuracy: 0.7087\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5975 - accuracy: 0.7055\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.5902 - accuracy: 0.7074\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5938 - accuracy: 0.7079\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 1s 17ms/step - loss: 0.5891 - accuracy: 0.7087\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5968 - accuracy: 0.7041\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.5926 - accuracy: 0.7087\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5940 - accuracy: 0.7060\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5932 - accuracy: 0.7072\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.5886 - accuracy: 0.7065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160acac7df0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "model=KerasClassifier(build_fn=rnn,epochs=20,batch_size=100)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "93051e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7159420289855073"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=model.predict(X_test)\n",
    "y_pred_encoded=to_categorical(y_pred,num_classes=2)\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94265391",
   "metadata": {},
   "source": [
    "### Testing on new Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "40968c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['r Free! Call The Mobile Update Co FREE on 08002986030']\n",
    "a=tokenizer.texts_to_sequences(a)\n",
    "a=np.array(a)\n",
    "a=pad_sequences(a,padding='post',maxlen=100)\n",
    "a=a.reshape((a.shape[0],a.shape[1],1))\n",
    "model.predict(np.array(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "097b5fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[741,   0],\n",
       "       [294,   0]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "10e523b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape=(100, 1), return_sequences=False))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))  # Update the number of units to 2 for binary classification\n",
    "    model.summary()\n",
    "\n",
    "    rmsprop = RMSprop(lr=0.001)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6d92eae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 100, 1)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a270dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d417b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 128)               6528      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,314\n",
      "Trainable params: 25,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\optimizers\\legacy\\rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filensya8xj0.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\losses.py\", line 1984, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"E:\\BROCAMP\\DS\\dsvenv\\lib\\site-packages\\keras\\backend.py\", line 5559, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f61f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsvenv",
   "language": "python",
   "name": "dsvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
